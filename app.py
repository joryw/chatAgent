"""Main Chainlit application for AI Agent with Model Invocation."""

import asyncio
import logging
import os
from typing import Optional

import chainlit as cl
from chainlit.input_widget import Switch
from dotenv import load_dotenv

from src.config.model_config import (
    ModelProvider,
    get_model_config,
    get_available_providers,
)
from src.config.search_config import get_search_config, is_search_available
from src.models.factory import get_model_wrapper
from src.prompts.templates import (
    DEFAULT_SYSTEM_MESSAGE,
    count_prompt_tokens,
    build_system_message_with_search,
)
from src.search.search_service import SearchService

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=os.getenv("LOG_LEVEL", "INFO"),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# Global caches (initialized once at first session start)
_global_search_service: Optional[SearchService] = None
_search_service_initialized = False
_search_initialization_lock = asyncio.Lock()

_global_model_wrappers = {}  # Cache for model wrappers by provider
_model_initialization_lock = asyncio.Lock()


async def get_or_create_model_wrapper(provider: str):
    """Get cached model wrapper or create new one.
    
    Model wrappers are cached per provider to avoid repeated initialization.
    """
    global _global_model_wrappers
    
    # Return cached wrapper if exists
    if provider in _global_model_wrappers:
        logger.debug(f"Reusing cached model wrapper for provider: {provider}")
        return _global_model_wrappers[provider]
    
    async with _model_initialization_lock:
        # Double-check after acquiring lock
        if provider in _global_model_wrappers:
            return _global_model_wrappers[provider]
        
        # Create new wrapper
        logger.info(f"ğŸ¤– Initializing model wrapper for provider: {provider} (one-time setup)...")
        model_wrapper = get_model_wrapper(provider=provider)
        _global_model_wrappers[provider] = model_wrapper
        logger.info(f"âœ… Model wrapper initialized: {model_wrapper.config.model_name}")
        
        return model_wrapper


async def initialize_search_service() -> Optional[SearchService]:
    """Initialize search service once and cache the result.
    
    This function is called only once when the first user session starts.
    Subsequent sessions will reuse the cached search service.
    """
    global _global_search_service, _search_service_initialized
    
    # Double-check pattern with lock
    if _search_service_initialized:
        return _global_search_service
    
    async with _search_initialization_lock:
        # Check again after acquiring lock
        if _search_service_initialized:
            return _global_search_service
        
        search_available = is_search_available()
        if not search_available:
            _search_service_initialized = True
            return None
        
        try:
            logger.info("ğŸ” Initializing search service (one-time setup)...")
            search_config = get_search_config()
            search_service = SearchService(
                searxng_url=search_config.searxng_url,
                timeout=search_config.timeout,
                max_results=search_config.max_results,
                max_content_length=search_config.max_content_length,
            )
            
            # Perform one-time health check
            health_ok = await search_service.client.health_check()
            
            if health_ok:
                logger.info("âœ… Search service initialized successfully")
                _global_search_service = search_service
            else:
                logger.warning(
                    "âš ï¸ SearXNG health check failed. Search will be unavailable.\n"
                    "ğŸ“– Deployment guide: docs/guides/searxng-deployment.md"
                )
                _global_search_service = None
        
        except Exception as e:
            logger.error(
                f"âŒ Failed to initialize search service: {str(e)}\n"
                "Search functionality will be unavailable.\n"
                "To enable search:\n"
                "  1. Deploy SearXNG locally (see docs/guides/searxng-deployment.md)\n"
                "  2. Ensure SEARXNG_URL in .env points to your instance\n"
                "  3. Run verification: bash openspec/changes/update-searxng-local-deployment/verify-searxng.sh"
            )
            _global_search_service = None
        
        _search_service_initialized = True
        return _global_search_service


@cl.on_settings_update
async def settings_update(settings):
    """Handle chat settings updates."""
    try:
        search_enabled = settings.get("web_search", False)
        search_service = cl.user_session.get("search_service")
        
        if search_service:
            # Update search enabled state
            cl.user_session.set("search_enabled", search_enabled)
            
            # Send confirmation message
            status = "âœ… å·²å¯ç”¨" if search_enabled else "âŒ å·²ç¦ç”¨"
            await cl.Message(
                content=f"è”ç½‘æœç´¢ {status}",
                author="System",
            ).send()
        else:
            # Search service not available
            await cl.Message(
                content="âš ï¸ æœç´¢æœåŠ¡ä¸å¯ç”¨ï¼Œæ— æ³•å¯ç”¨è”ç½‘æœç´¢ã€‚\n\nè¯·æ£€æŸ¥ SearXNG é…ç½®ã€‚",
                author="System",
            ).send()
    
    except Exception as e:
        logger.error(f"Error updating settings: {str(e)}")
        await cl.Message(
            content=f"âŒ è®¾ç½®æ›´æ–°å¤±è´¥: {str(e)}",
            author="System",
        ).send()


@cl.on_chat_start
async def start():
    """Initialize chat session."""
    try:
        # Get available providers
        available_providers = get_available_providers()
        
        if not available_providers:
            await cl.Message(
                content="âš ï¸ No model providers configured. Please set up API keys in .env file.",
                author="System",
            ).send()
            return
        
        # Get default provider
        default_provider = os.getenv("DEFAULT_PROVIDER", "openai")
        if default_provider not in available_providers:
            default_provider = available_providers[0]
        
        # Get cached model wrapper (initialized once per provider)
        try:
            model_wrapper = await get_or_create_model_wrapper(provider=default_provider)
            config = model_wrapper.config
            
            # Get cached search service (initialized once on first session)
            search_service = await initialize_search_service()
            search_available = search_service is not None
            
            # Store in session
            cl.user_session.set("model_wrapper", model_wrapper)
            cl.user_session.set("current_provider", default_provider)
            cl.user_session.set("available_providers", available_providers)
            cl.user_session.set("conversation_history", [])
            cl.user_session.set("search_service", search_service)
            cl.user_session.set("search_enabled", False)  # Default off
            
            # Prepare welcome message first
            if search_available and search_service:
                search_status = "âœ… å¯ç”¨ (æœ¬åœ°éƒ¨ç½²)"
                search_hint = ""
            else:
                search_status = "âŒ ä¸å¯ç”¨"
                search_hint = "\n\nğŸ’¡ **å¯ç”¨è”ç½‘æœç´¢:**\n1. éƒ¨ç½² SearXNG: `docs/guides/searxng-deployment.md`\n2. é…ç½® `.env`: `SEARXNG_URL=http://localhost:8080`\n3. é‡å¯åº”ç”¨\n"
            
            welcome_msg = f"""# ğŸ¤– Welcome to AI Agent Chat!

**Current Model:** {config.model_name}
**Provider:** {config.provider}
**Temperature:** {config.temperature}
**Max Tokens:** {config.max_tokens}

**Available Providers:** {', '.join(available_providers)}
**è”ç½‘æœç´¢:** {search_status}{search_hint}

You can start chatting now! Type your message below.

**ğŸ’¡ ä½¿ç”¨ UI å¼€å…³:**
- ç‚¹å‡»å³ä¸Šè§’ âš™ï¸ å›¾æ ‡æ‰“å¼€è®¾ç½®é¢æ¿
- åˆ‡æ¢ "ğŸ” è”ç½‘æœç´¢" å¼€å…³å³å¯å¯ç”¨/ç¦ç”¨æœç´¢åŠŸèƒ½
- å¼€å…³çŠ¶æ€ä¼šç«‹å³ç”Ÿæ•ˆ

**Commands (å¤‡ç”¨æ–¹å¼):**
- `/switch <provider>` - Switch to a different model provider
- `/search <on|off>` - Enable or disable web search (also via UI toggle)
- `/config` - View current configuration
- `/reset` - Clear conversation history
- `/help` - Show this help message
"""
            
            # Send welcome message and chat settings simultaneously
            # This prevents showing a blank screen before content appears
            welcome_message = cl.Message(
                content=welcome_msg,
                author="System",
            )
            
            chat_settings = cl.ChatSettings(
                [
                    Switch(
                        id="web_search",
                        label="ğŸ” è”ç½‘æœç´¢",
                        initial=False,
                        description="å¯ç”¨åå°†ä½¿ç”¨ SearXNG æœç´¢å®æ—¶ä¿¡æ¯",
                        disabled=(search_service is None),
                    )
                ]
            )
            
            # Send both at the same time to avoid double window flash
            await asyncio.gather(
                welcome_message.send(),
                chat_settings.send()
            )
            
        except Exception as e:
            logger.error(f"Failed to initialize model: {str(e)}")
            await cl.Message(
                content=f"âŒ Error initializing model: {str(e)}\n\nPlease check your .env configuration.",
                author="System",
            ).send()
    
    except Exception as e:
        logger.error(f"Error in chat start: {str(e)}")
        await cl.Message(
            content=f"âŒ Initialization error: {str(e)}",
            author="System",
        ).send()




@cl.on_message
async def main(message: cl.Message):
    """Handle incoming messages."""
    try:
        user_message = message.content.strip()
        
        # Handle commands
        if user_message.startswith("/"):
            await handle_command(user_message)
            return
        
        # Get model wrapper from session
        model_wrapper = cl.user_session.get("model_wrapper")
        if not model_wrapper:
            await cl.Message(
                content="âš ï¸ Model not initialized. Please restart the chat.",
                author="System",
            ).send()
            return
        
        # Check if search is enabled
        search_enabled = cl.user_session.get("search_enabled", False)
        search_service = cl.user_session.get("search_service")
        
        # Perform search if enabled
        search_response = None
        search_results_text = None
        if search_enabled and search_service:
            try:
                # Show searching indicator
                search_msg = cl.Message(
                    content="ğŸ” æ­£åœ¨æœç´¢ç›¸å…³ä¿¡æ¯...",
                    author="System",
                )
                await search_msg.send()
                
                # Perform search
                search_response = await search_service.search(user_message)
                
                # Update search message
                if search_response and not search_response.is_empty():
                    search_msg.content = f"âœ… æ‰¾åˆ° {search_response.total_results} æ¡æœç´¢ç»“æœ"
                    await search_msg.update()
                    
                    # Format search results for prompt
                    search_results_text = search_service.format_for_prompt(search_response)
                else:
                    search_msg.content = "âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœï¼Œå°†åŸºäºæ¨¡å‹çŸ¥è¯†å›ç­”"
                    await search_msg.update()
            
            except Exception as e:
                logger.error(f"Search error: {str(e)}")
                await cl.Message(
                    content=f"âš ï¸ æœç´¢å¤±è´¥: {str(e)}\n\nå°†ç»§ç»­ä½¿ç”¨æ¨¡å‹çŸ¥è¯†å›ç­”ã€‚",
                    author="System",
                ).send()
        
        # Create response message
        response_msg = cl.Message(
            content="",
            author="Assistant",
        )
        await response_msg.send()
        
        try:
            # Build system message with search results if available
            system_message = build_system_message_with_search(
                DEFAULT_SYSTEM_MESSAGE,
                search_results_text,
            )
            
            # Count tokens
            token_count = count_prompt_tokens(
                user_message,
                system_message,
            )
            
            logger.info(f"Processing message with {token_count} tokens (search: {search_enabled})")
            
            # Generate streaming response
            full_response = ""
            async for chunk in model_wrapper.generate_stream(
                prompt=user_message,
                system_message=system_message,
            ):
                full_response += chunk.content
                response_msg.content = full_response
                await response_msg.update()
            
            # Display search sources if available
            if search_response and not search_response.is_empty():
                sources_text = search_service.format_sources(search_response)
                await cl.Message(
                    content=sources_text,
                    author="System",
                ).send()
            
            # Update conversation history
            history = cl.user_session.get("conversation_history", [])
            history.append({
                "role": "user",
                "content": user_message,
            })
            history.append({
                "role": "assistant",
                "content": full_response,
            })
            cl.user_session.set("conversation_history", history)
            
            # Count completion tokens (approximate)
            completion_tokens = model_wrapper.count_tokens(full_response)
            total_tokens = token_count + completion_tokens
            
            # Send metadata as a separate message
            search_info = f"\n- Search: {'Enabled âœ…' if search_enabled else 'Disabled'}"
            if search_enabled and search_response:
                search_info += f" ({search_response.total_results} results)"
            
            metadata_msg = f"""
---
**ğŸ“Š Response Metadata:**
- Model: {model_wrapper.config.model_name}
- Tokens Used: ~{total_tokens} (prompt: ~{token_count}, completion: ~{completion_tokens}){search_info}
"""
            
            await cl.Message(
                content=metadata_msg,
                author="System",
            ).send()
        
        except Exception as e:
            logger.error(f"Error generating response: {str(e)}")
            response_msg.content = f"âŒ Error generating response: {str(e)}\n\nPlease try again."
            await response_msg.update()
    
    except Exception as e:
        logger.error(f"Error in message handler: {str(e)}")
        await cl.Message(
            content=f"âŒ Error: {str(e)}",
            author="System",
        ).send()


async def handle_command(command: str):
    """Handle slash commands.
    
    Args:
        command: Command string (e.g., '/switch openai')
    """
    parts = command.split(maxsplit=1)
    cmd = parts[0].lower()
    args = parts[1] if len(parts) > 1 else ""
    
    if cmd == "/help":
        help_msg = """# ğŸ“– Available Commands

**ğŸ’¡ æ¨èä½¿ç”¨ UI å¼€å…³:**
- ç‚¹å‡»å³ä¸Šè§’ âš™ï¸ å›¾æ ‡æ‰“å¼€è®¾ç½®é¢æ¿
- ç›´æ¥åˆ‡æ¢ "ğŸ” è”ç½‘æœç´¢" å¼€å…³

**å‘½ä»¤åˆ—è¡¨ (å¤‡ç”¨æ–¹å¼):**
- `/switch <provider>` - Switch to a different model provider (openai, anthropic, deepseek)
- `/search <on|off>` - Enable or disable web search (æ¨èä½¿ç”¨UIå¼€å…³)
- `/config` - View current configuration
- `/reset` - Clear conversation history
- `/help` - Show this help message

**Examples:**
```
/switch deepseek
/search on
/search off
```
"""
        await cl.Message(content=help_msg, author="System").send()
    
    elif cmd == "/config":
        model_wrapper = cl.user_session.get("model_wrapper")
        if not model_wrapper:
            await cl.Message(
                content="âš ï¸ No model configured.",
                author="System",
            ).send()
            return
        
        config = model_wrapper.config
        search_enabled = cl.user_session.get("search_enabled", False)
        search_service = cl.user_session.get("search_service")
        search_status = "âœ… Enabled" if search_enabled else "âŒ Disabled"
        if not search_service:
            search_status = "âš ï¸ Not Available"
        
        config_msg = f"""# âš™ï¸ Current Configuration

**Provider:** {config.provider}
**Model:** {config.model_name}
**Temperature:** {config.temperature}
**Max Tokens:** {config.max_tokens}
**Top P:** {config.top_p}
**Timeout:** {config.timeout}s

**Web Search:** {search_status}

**Available Providers:** {', '.join(cl.user_session.get('available_providers', []))}

ğŸ’¡ **æç¤º:** å¯é€šè¿‡å³ä¸Šè§’ âš™ï¸ è®¾ç½®é¢æ¿åˆ‡æ¢è”ç½‘æœç´¢å¼€å…³
"""
        await cl.Message(content=config_msg, author="System").send()
    
    elif cmd == "/reset":
        cl.user_session.set("conversation_history", [])
        await cl.Message(
            content="âœ… Conversation history cleared.",
            author="System",
        ).send()
    
    elif cmd == "/search":
        if not args:
            search_enabled = cl.user_session.get("search_enabled", False)
            search_service = cl.user_session.get("search_service")
            
            if not search_service:
                await cl.Message(
                    content="âš ï¸ Web search is not available. Please check your SEARXNG_URL configuration.",
                    author="System",
                ).send()
                return
            
            status = "âœ… Enabled" if search_enabled else "âŒ Disabled"
            await cl.Message(
                content=f"""# ğŸ” Web Search Status

**Current Status:** {status}

To change: `/search on` or `/search off`
""",
                author="System",
            ).send()
            return
        
        action = args.lower().strip()
        search_service = cl.user_session.get("search_service")
        
        if not search_service:
            await cl.Message(
                content="âš ï¸ Web search is not available. Please check your SEARXNG_URL configuration.",
                author="System",
            ).send()
            return
        
        if action == "on":
            cl.user_session.set("search_enabled", True)
            await cl.Message(
                content="âœ… Web search **enabled**\n\nNow you can ask questions that require real-time information!",
                author="System",
            ).send()
        elif action == "off":
            cl.user_session.set("search_enabled", False)
            await cl.Message(
                content="âŒ Web search **disabled**\n\nThe AI will respond using its built-in knowledge only.",
                author="System",
            ).send()
        else:
            await cl.Message(
                content="âš ï¸ Invalid option. Use `/search on` or `/search off`",
                author="System",
            ).send()
    
    elif cmd == "/switch":
        if not args:
            await cl.Message(
                content="âš ï¸ Please specify a provider: `/switch <provider>`\n\nAvailable: openai, anthropic, deepseek",
                author="System",
            ).send()
            return
        
        provider = args.lower().strip()
        available = cl.user_session.get("available_providers", [])
        
        if provider not in available:
            await cl.Message(
                content=f"âš ï¸ Provider '{provider}' not available or not configured.\n\nAvailable providers: {', '.join(available)}",
                author="System",
            ).send()
            return
        
        try:
            # Get cached model wrapper (or create if first time for this provider)
            model_wrapper = await get_or_create_model_wrapper(provider=provider)
            config = model_wrapper.config
            
            # Update session
            cl.user_session.set("model_wrapper", model_wrapper)
            cl.user_session.set("current_provider", provider)
            
            # Clear history
            cl.user_session.set("conversation_history", [])
            
            await cl.Message(
                content=f"""âœ… Switched to **{provider}**

**Model:** {config.model_name}
**Temperature:** {config.temperature}
**Max Tokens:** {config.max_tokens}

Conversation history has been cleared.
""",
                author="System",
            ).send()
        
        except Exception as e:
            logger.error(f"Error switching provider: {str(e)}")
            await cl.Message(
                content=f"âŒ Error switching provider: {str(e)}",
                author="System",
            ).send()
    
    else:
        await cl.Message(
            content=f"âš ï¸ Unknown command: {cmd}\n\nType `/help` for available commands.",
            author="System",
        ).send()


if __name__ == "__main__":
    # This is handled by Chainlit CLI
    pass

