# OpenAI API Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_TEMPERATURE=0.7
OPENAI_MAX_TOKENS=2000

# Anthropic API Configuration (optional)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_MAX_TOKENS=2000

# DeepSeek API Configuration
DEEPSEEK_API_KEY=sk-your-deepseek-api-key-here
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_TEMPERATURE=0.7
# max_tokens (output length) valid range:
# - deepseek-chat: [1, 8192] (8K max)
# - deepseek-reasoner: [1, 65536] (64K max)
# Note: Context length (input) is 128K for both models
DEEPSEEK_MAX_TOKENS=2000

# DeepSeek Model Variant (deepseek-chat or deepseek-reasoner)
# - deepseek-chat: Standard conversational model
# - deepseek-reasoner: Reasoning model with thinking process display
# Note: Can be switched via UI settings panel (recommended)
DEEPSEEK_MODEL_VARIANT=deepseek-chat

# Default Model Provider (openai, anthropic, or deepseek)
DEFAULT_PROVIDER=openai

# Default Conversation Mode (chat or agent)
# - chat: Regular conversation with manual search control
# - agent: Autonomous decision-making with ReAct loop
DEFAULT_MODE=chat

# Logging Level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Web Search Configuration
SEARCH_ENABLED=false

# SearXNG Configuration
# IMPORTANT: Use local deployment for stable search functionality
# See docs/guides/searxng-deployment.md for deployment instructions
#
# Deployment options:
# 1. Local Docker instance (RECOMMENDED): http://localhost:8080
#    - Stable and reliable
#    - No rate limiting
#    - Complete control
#    - Deploy with: docker compose up -d
#
# 2. Custom port: http://localhost:9090
#    - If port 8080 is occupied
#
# 3. Remote instance: http://192.168.1.100:8080
#    - If deployed on another machine
#
# ‚ö†Ô∏è  NOT RECOMMENDED: Public instances (unstable, may not work)
# SEARXNG_URL=https://searx.be
#
# üìñ Quick deployment:
#    cp openspec/changes/update-searxng-local-deployment/docker-compose.yml.example searxng/docker-compose.yml
#    cd searxng && docker compose up -d
#    Verify: bash openspec/changes/update-searxng-local-deployment/verify-searxng.sh
SEARXNG_URL=http://localhost:8080

# Search parameters
SEARCH_TIMEOUT=5.0
SEARCH_MAX_RESULTS=5
SEARCH_MAX_CONTENT_LENGTH=200
SEARCH_LANGUAGE=auto
SEARCH_SAFESEARCH=1

# Agent Mode Configuration
# Maximum number of ReAct iterations (1-10)
AGENT_MAX_ITERATIONS=5

# Maximum execution time in seconds (10-300)
AGENT_MAX_EXECUTION_TIME=60

# Whether to output detailed logs
AGENT_VERBOSE=true

# Whether to enable search result caching
AGENT_ENABLE_CACHE=true

# LangSmith Monitoring Configuration (optional)
# LangSmith is a monitoring and debugging platform for LangChain applications
# Get your API key from: https://smith.langchain.com/
#
# To enable LangSmith monitoring:
# 1. Sign up at https://smith.langchain.com/
# 2. Get your API key from the settings page
# 3. Set LANGSMITH_API_KEY in your .env file
# 4. Optionally set LANGSMITH_PROJECT to organize traces by project
#
# If not configured, monitoring is disabled and the application works normally
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=chatagent-dev
# Optional: Custom LangSmith API endpoint (for self-hosted instances)
# LANGSMITH_API_URL=https://api.smith.langchain.com

