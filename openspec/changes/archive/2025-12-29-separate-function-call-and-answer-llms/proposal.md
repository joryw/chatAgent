# Change: 分离 Function Call 和最终回答的 LLM

## Why

当前 ReAct Agent 使用同一个 LLM 模型同时负责工具调用决策和最终回答生成。这种设计存在以下问题：

1. **成本优化不足**：工具调用决策通常需要快速、经济的模型，而最终回答可能需要更高质量、更昂贵的模型
2. **性能优化受限**：无法针对不同阶段选择最适合的模型（例如，使用快速模型做决策，使用高质量模型生成回答）
3. **灵活性不足**：用户无法独立配置工具调用模型和回答生成模型，限制了使用场景的灵活性

通过分离这两个阶段，系统可以：
- 使用更经济的模型进行工具调用决策，降低总体成本
- 使用更高质量的模型生成最终回答，提升用户体验
- 允许用户根据需求灵活配置不同阶段的模型

## What Changes

- **ADDED**: 支持为 Agent 配置两个独立的 LLM 模型
  - `function_call_llm`: 负责工具调用决策的模型
  - `answer_llm`: 负责生成最终回答的模型
- **MODIFIED**: ReAct Agent 执行流程
  - 工具调用阶段使用 `function_call_llm`
  - 当工具调用结果满足要求后，切换到 `answer_llm` 生成最终回答
- **ADDED**: 工具调用结果评估机制
  - 判断工具调用结果是否足够回答用户问题
  - 决定何时停止工具调用循环并切换到回答生成
- **ADDED**: 配置接口支持双模型配置
  - 环境变量支持分别配置两个模型
  - UI 设置面板支持独立选择两个模型
- **MODIFIED**: Agent 执行过程展示
  - 明确标识当前使用的模型（工具调用阶段 vs 回答生成阶段）

## Impact

- **Affected specs**: 
  - `agent-mode`: 需要修改 Agent 执行流程和配置要求
  - `model-invocation`: 需要支持多模型实例管理
- **Affected code**: 
  - `src/agents/react_agent.py`: 核心 Agent 实现需要重构
  - `src/config/agent_config.py`: 需要添加双模型配置支持
  - `app.py`: UI 需要支持双模型配置界面
- **Breaking changes**: 
  - Agent 初始化接口需要修改，支持传入两个 LLM 实例
  - 配置格式需要更新，但保持向后兼容（如果只提供一个模型，则两个阶段使用同一模型）

